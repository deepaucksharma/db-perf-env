###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\.env ######
# Database Configuration
MYSQL_ROOT_PASSWORD=secure_root_pw123
MYSQL_DATABASE=employees
MYSQL_USER=myuser
MYSQL_PASSWORD=userpass123
MYSQL_HOST=mysql-db
MYSQL_PORT=3306

# Monitor User Configuration
MYSQL_MONITOR_USER=monitor
MYSQL_MONITOR_PASSWORD=monitorpass123

# Performance Settings
BATCH_SIZE=1000
TOTAL_EMPLOYEES=10000

# API Configuration
API_PORT=3000

# Load Generator Configuration
K6_VUS=50
K6_DURATION=30m
NEW_RELIC_LICENSE_KEY=eu01xx0ce15fea0f04db4b9d9ecce89dFFFFNRAL
NEW_RELIC_APP_NAME=MySQL-Perf-Demo
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\.env.example ######
MYSQL_ROOT_PASSWORD=demo123
MYSQL_DATABASE=employees
MYSQL_USER=myuser
MYSQL_PASSWORD=demopass

# New Relic MySQL Monitor User
MYSQL_MONITOR_USER=newrelic
MYSQL_MONITOR_PASSWORD=nrpass123

# API Configuration
API_PORT=3000

# Data Generation
BATCH_SIZE=5000
TOTAL_EMPLOYEES=100000

# Performance Testing
ENABLE_SLOW_QUERIES=true
SLOW_QUERY_TIME=0.5

# Load Generator Configuration
K6_VUS=100
K6_DURATION=30m

# New Relic Configuration
NEW_RELIC_LICENSE_KEY=your_license_key
NEW_RELIC_APP_NAME=MySQL-Demo

# Environment
NODE_ENV=development

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\.gitignore ######
# Environment files
.env*
!.env.example

# Logs
*.log
logs/
mysql_logs/

# Dependencies
node_modules/
__pycache__/
*.pyc

# IDE and editors
.vscode/
.idea/
*.swp
*.swo
*~

# Build and data directories
mysql_data/
data/

# Docker
.docker/
docker-compose.override.yml

# Temporary files
*.tmp
*.temp
.DS_Store

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\combined_content.txt ######
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\.env ######
# Database Configuration
MYSQL_ROOT_PASSWORD=secure_root_pw123
MYSQL_DATABASE=employees
MYSQL_USER=myuser
MYSQL_PASSWORD=userpass123
MYSQL_HOST=mysql-db
MYSQL_PORT=3306

# Monitor User Configuration
MYSQL_MONITOR_USER=monitor
MYSQL_MONITOR_PASSWORD=monitorpass123

# Performance Settings
BATCH_SIZE=1000
TOTAL_EMPLOYEES=10000

# API Configuration
API_PORT=3000

# Load Generator Configuration
K6_VUS=50
K6_DURATION=30m
NEW_RELIC_LICENSE_KEY=eu01xx0ce15fea0f04db4b9d9ecce89dFFFFNRAL
NEW_RELIC_APP_NAME=MySQL-Perf-Demo
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\.env.example ######
MYSQL_ROOT_PASSWORD=demo123
MYSQL_DATABASE=employees
MYSQL_USER=myuser
MYSQL_PASSWORD=demopass

# New Relic MySQL Monitor User
MYSQL_MONITOR_USER=newrelic
MYSQL_MONITOR_PASSWORD=nrpass123

# API Configuration
API_PORT=3000

# Data Generation
BATCH_SIZE=5000
TOTAL_EMPLOYEES=100000

# Performance Testing
ENABLE_SLOW_QUERIES=true
SLOW_QUERY_TIME=0.5

# Load Generator Configuration
K6_VUS=100
K6_DURATION=30m

# New Relic Configuration
NEW_RELIC_LICENSE_KEY=your_license_key
NEW_RELIC_APP_NAME=MySQL-Demo

# Environment
NODE_ENV=development

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\.gitignore ######
# Environment files
.env*
!.env.example

# Logs
*.log
logs/
mysql_logs/

# Dependencies
node_modules/
__pycache__/
*.pyc

# IDE and editors
.vscode/
.idea/
*.swp
*.swo
*~

# Build and data directories
mysql_data/
data/

# Docker
.docker/
docker-compose.override.yml

# Temporary files
*.tmp
*.temp
.DS_Store


###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\docker-compose.yml ######
services:
  mysql:
    build:
      context: ./db-setup
      dockerfile: Dockerfile
    container_name: mysql-db
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_MONITOR_USER: ${MYSQL_MONITOR_USER}
      MYSQL_MONITOR_PASSWORD: ${MYSQL_MONITOR_PASSWORD}
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - mysql_logs:/var/log/mysql
      - ./db-setup/config:/etc/mysql/conf.d
    networks:
      - backend
    healthcheck:
      test: mysqladmin ping -h localhost -u $$MYSQL_USER --password=$$MYSQL_PASSWORD
      interval: 10s
      timeout: 5s
      retries: 3

  api:
    build:
      context: ./services/api
      dockerfile: Dockerfile
    container_name: employees-api
    environment:
      MYSQL_HOST: mysql-db
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      API_PORT: ${API_PORT}
      NEW_RELIC_LICENSE_KEY: ${NEW_RELIC_LICENSE_KEY}
      NEW_RELIC_APP_NAME: ${NEW_RELIC_APP_NAME}
      NODE_ENV: production
    volumes:
      - api_logs:/var/log/newrelic
    ports:
      - "${API_PORT}:3000"
    depends_on:
      mysql:
        condition: service_healthy
    networks:
      - backend

  load-generator:
    build:
      context: ./services/load-generator
      dockerfile: Dockerfile
    environment:
      API_URL: http://api:3000
      K6_VUS: ${K6_VUS}
      K6_DURATION: ${K6_DURATION}
      NEW_RELIC_LICENSE_KEY: ${NEW_RELIC_LICENSE_KEY}
    depends_on:
      - api
    networks:
      - backend

  newrelic-infra:
    image: newrelic/infrastructure:latest
    container_name: newrelic-infra
    user: root
    cap_add:
      - SYS_PTRACE
    pid: host
    environment:
      - NRIA_LICENSE_KEY=${NEW_RELIC_LICENSE_KEY}
      - NRIA_DISPLAY_NAME=MySQL-Performance-Demo
    volumes:
      - /:/host:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - ./infrastructure/newrelic/newrelic-infra.yml:/etc/newrelic-infra.yml
      - newrelic_logs:/var/log/newrelic-infra
    networks:
      - backend
    depends_on:
      mysql:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
        mkdir -p /var/log/newrelic-infra &&
        chmod -R 777 /var/log/newrelic-infra &&
        /usr/bin/newrelic-infra
      "

  newrelic-mysql:
    image: newrelic/infrastructure:latest
    container_name: newrelic-mysql
    pid: host
    environment:
      - NRIA_LICENSE_KEY=${NEW_RELIC_LICENSE_KEY}
      - MYSQL_HOSTNAME=mysql-db
      - MYSQL_PORT=3306
      - MYSQL_USERNAME=${MYSQL_MONITOR_USER}
      - MYSQL_PASSWORD=${MYSQL_MONITOR_PASSWORD}
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - ./infrastructure/newrelic/mysql-config.yml:/etc/newrelic-infra/integrations.d/mysql-config.yml
    networks:
      - backend
    depends_on:
      mysql:
        condition: service_healthy

networks:
  backend:
    driver: bridge

volumes:
  mysql_data:
  mysql_logs:
  newrelic_logs:
  api_logs:
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\config\mysql.cnf ######
# MySQL Configuration
[mysqld]
bind-address = 0.0.0.0
port = 3306
default-storage-engine = InnoDB
innodb_buffer_pool_size = 1G

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\config\performance-schema.cnf ######
# Performance Schema Configuration
[mysqld]
performance_schema = ON
performance_schema_instrument = 'statement/sql/*=ON'
performance_schema_consumer_events_statements_history = ON
performance_schema_consumer_events_statements_history_long = ON

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\combined_content.txt ######
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\combined_content.txt ######

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\Dockerfile ######
FROM mysql:8.0

# Install required utilities
RUN microdnf update && \
    microdnf install -y curl python3 python3-pip && \
    microdnf clean all

# Create required directories
RUN mkdir -p /var/log/mysql /scripts /docker-entrypoint-initdb.d && \
    chown mysql:mysql /var/log/mysql && \
    chmod 755 /var/log/mysql

# Copy configuration files
COPY config/ /etc/mysql/conf.d/
RUN chown -R mysql:mysql /etc/mysql/conf.d/ && \
    chmod 0444 /etc/mysql/conf.d/*.cnf

# Copy initialization files
COPY migrations/ /docker-entrypoint-initdb.d/
RUN chmod -R 0755 /docker-entrypoint-initdb.d/

# Copy Python scripts and requirements
COPY scripts/ /scripts/
COPY requirements.txt /scripts/

# Install Python dependencies
RUN pip3 install --no-cache-dir -r /scripts/requirements.txt && \
    rm -rf /root/.cache/pip

# Create healthcheck script
RUN echo '#!/bin/bash' > /healthcheck.sh && \
    echo 'mysqladmin ping -h"localhost" -u"$MYSQL_USER" -p"$MYSQL_PASSWORD" --silent' >> /healthcheck.sh && \
    chmod +x /healthcheck.sh

EXPOSE 3306

HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD ["/healthcheck.sh"]

CMD ["mysqld"]

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\requirements.txt ######
mysql-connector-python==8.0.28

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\config\mysql.cnf ######
[mysqld]
# InnoDB Settings
innodb_buffer_pool_size = 1G
innodb_buffer_pool_instances = 2
innodb_file_per_table = 1
innodb_flush_log_at_trx_commit = 2
innodb_log_buffer_size = 16M
innodb_io_capacity = 1000
innodb_flush_method = O_DIRECT
innodb_thread_concurrency = 0

# Buffer Settings
sort_buffer_size = 1M
read_buffer_size = 1M
join_buffer_size = 1M
tmp_table_size = 32M
max_heap_table_size = 32M

# Connection Settings
max_connections = 100
thread_cache_size = 50
wait_timeout = 28800
interactive_timeout = 28800

# Slow Query Logging
slow_query_log = 1
slow_query_log_file = /var/log/mysql/slow.log
long_query_time = ${SLOW_QUERY_TIME}
log_queries_not_using_indexes = 1

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\config\performance-schema.cnf ######
[mysqld]
# Enable Performance Schema
performance_schema = ON
performance_schema_max_digest_length = 4096
performance_schema_max_sql_text_length = 4096

# Instrument Configuration
performance_schema_instrument = 'memory/%=ON'
performance_schema_instrument = 'statement/%=ON'
performance_schema_instrument = 'wait/lock/metadata/sql/mdl=ON'
performance_schema_instrument = 'wait/lock/table/sql/handler=ON'
performance_schema_instrument = 'table/%=ON'

# Consumer Configuration
performance_schema_consumer_events_statements_current = ON
performance_schema_consumer_events_statements_history = ON
performance_schema_consumer_events_statements_history_long = ON
performance_schema_consumer_statements_digest = ON

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\migrations\01_init_schema.sql ######
-- Initialize database and tables
CREATE DATABASE IF NOT EXISTS employees;
USE employees;

-- Create departments table
CREATE TABLE IF NOT EXISTS departments (
    dept_no CHAR(4) PRIMARY KEY,
    dept_name VARCHAR(40) NOT NULL,
    manager_budget DECIMAL(15,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    UNIQUE KEY uk_dept_name (dept_name)
);

-- Create employees table
CREATE TABLE IF NOT EXISTS employees (
    emp_no INT PRIMARY KEY,
    birth_date DATE NOT NULL,
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    gender ENUM('M','F') NOT NULL,
    hire_date DATE NOT NULL,
    birth_month INT GENERATED ALWAYS AS (MONTH(birth_date)) STORED,
    hire_year INT GENERATED ALWAYS AS (YEAR(hire_date)) STORED,
    salary_tier INT GENERATED ALWAYS AS (
        CASE 
            WHEN emp_no % 4 = 0 THEN 1
            WHEN emp_no % 4 = 1 THEN 2
            WHEN emp_no % 4 = 2 THEN 3
            ELSE 4
        END
    ) STORED,
    last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Create salaries table
CREATE TABLE IF NOT EXISTS salaries (
    id INT AUTO_INCREMENT PRIMARY KEY,
    emp_no INT NOT NULL,
    salary INT NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    FOREIGN KEY (emp_no) REFERENCES employees (emp_no) ON DELETE CASCADE
);

-- Create dept_emp table
CREATE TABLE IF NOT EXISTS dept_emp (
    emp_no INT NOT NULL,
    dept_no CHAR(4) NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    PRIMARY KEY (emp_no, dept_no),
    FOREIGN KEY (emp_no) REFERENCES employees (emp_no) ON DELETE CASCADE,
    FOREIGN KEY (dept_no) REFERENCES departments (dept_no) ON DELETE CASCADE
);

-- Create indexes
CREATE INDEX idx_employees_gender ON employees(gender);
CREATE INDEX idx_employees_birth_month ON employees(birth_month);
CREATE INDEX idx_employees_hire_year ON employees(hire_year);
CREATE INDEX idx_emp_name1 ON employees(last_name, first_name);
CREATE INDEX idx_salary_tier ON employees(salary_tier);

CREATE INDEX idx_salaries_amount ON salaries(salary);
CREATE INDEX idx_salaries_dates ON salaries(from_date, to_date);

CREATE INDEX idx_dept_emp_dates ON dept_emp(from_date, to_date);

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\migrations\02_init_users.sh ######
#!/bin/bash
set -e

# Wait for MySQL to be ready
max_attempts=30
counter=0

until mysqladmin ping -h"localhost" -u"root" -p"${MYSQL_ROOT_PASSWORD}" --silent; do
    counter=$((counter + 1))
    if [ $counter -eq $max_attempts ]; then
        echo "Failed to connect to MySQL after $max_attempts attempts"
        exit 1
    fi
    echo "Attempt $counter of $max_attempts: MySQL not ready, waiting..."
    sleep 2
done

mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" <<EOSQL
-- Create users with basic permissions
CREATE USER IF NOT EXISTS '${MYSQL_USER}'@'%' IDENTIFIED BY '${MYSQL_PASSWORD}';
CREATE USER IF NOT EXISTS '${MYSQL_MONITOR_USER}'@'%' IDENTIFIED BY '${MYSQL_MONITOR_PASSWORD}';

-- Grant permissions to application user
GRANT ALL PRIVILEGES ON ${MYSQL_DATABASE}.* TO '${MYSQL_USER}'@'%';

-- Grant monitoring permissions
GRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON performance_schema.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON sys.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON information_schema.* TO '${MYSQL_MONITOR_USER}'@'%';

-- Enable performance monitoring
UPDATE performance_schema.setup_instruments 
SET ENABLED = 'YES', TIMED = 'YES'
WHERE NAME LIKE '%statement/%' 
   OR NAME LIKE '%stage/%'
   OR NAME LIKE '%wait/%'
   OR NAME LIKE '%memory/%';

UPDATE performance_schema.setup_consumers
SET ENABLED = 'YES'
WHERE NAME LIKE '%events%';

FLUSH PRIVILEGES;
EOSQL

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\create_tables.py ######
import mysql.connector
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_tables():
    db_config = {
        'host': os.getenv('MYSQL_HOST', 'localhost'),
        'user': os.getenv('MYSQL_USER', 'root'),
        'password': os.getenv('MYSQL_ROOT_PASSWORD', 'demo123'),
        'database': os.getenv('MYSQL_DATABASE', 'employees')
    }
    
    try:
        conn = mysql.connector.connect(**db_config)
        cursor = conn.cursor()
        
        # Create departments table if not exists
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS departments (
                dept_no CHAR(4) PRIMARY KEY,
                dept_name VARCHAR(40) NOT NULL,
                manager_budget DECIMAL(15,2),
                UNIQUE KEY uk_dept_name (dept_name)
            )
        """)
        
        # Create employees table if not exists
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS employees (
                emp_no INT PRIMARY KEY,
                birth_date DATE NOT NULL,
                first_name VARCHAR(50) NOT NULL,
                last_name VARCHAR(50) NOT NULL,
                gender ENUM('M','F') NOT NULL,
                hire_date DATE NOT NULL,
                birth_month INT GENERATED ALWAYS AS (MONTH(birth_date)) STORED,
                hire_year INT GENERATED ALWAYS AS (YEAR(hire_date)) STORED,
                salary_tier INT GENERATED ALWAYS AS (
                    CASE 
                        WHEN emp_no % 4 = 0 THEN 1
                        WHEN emp_no % 4 = 1 THEN 2
                        WHEN emp_no % 4 = 2 THEN 3
                        ELSE 4
                    END
                ) STORED
            )
        """)
        
        conn.commit()
        logger.info("Tables created successfully")
        
    except Exception as e:
        logger.error(f"Error creating tables: {str(e)}")
        conn.rollback()
        raise
    finally:
        if 'conn' in locals():
            cursor.close()
            conn.close()

if __name__ == "__main__":
    create_tables()
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\departments_data.py ######
#!/usr/bin/env python3
import mysql.connector
import os
import logging
from mysql.connector import Error

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DEPARTMENTS = [
    ('d001', 'Marketing'),
    ('d002', 'Finance'),
    ('d003', 'Human Resources'),
    ('d004', 'Research and Development'),
    ('d005', 'Quality Assurance'),
    ('d006', 'Sales'),
    ('d007', 'IT'),
    ('d008', 'Operations'),
    ('d009', 'Customer Support'),
    ('d010', 'Product Management')
]

def get_db_config():
    return {
        'host': os.getenv('MYSQL_HOST', 'localhost'),
        'user': os.getenv('MYSQL_USER', 'myuser'),
        'password': os.getenv('MYSQL_PASSWORD', 'userpass123'),
        'database': os.getenv('MYSQL_DATABASE', 'employees')
    }

def main():
    try:
        conn = mysql.connector.connect(**get_db_config())
        cursor = conn.cursor()
        
        # Insert departments
        cursor.executemany("""
            INSERT INTO departments (dept_no, dept_name)
            VALUES (%s, %s)
            ON DUPLICATE KEY UPDATE dept_name = VALUES(dept_name)
        """, DEPARTMENTS)
        
        # Initialize manager_budget randomly
        cursor.execute("""
            UPDATE departments 
            SET manager_budget = FLOOR(1000000 + RAND() * 1000000)
            WHERE manager_budget IS NULL
        """)
        
        conn.commit()
        logger.info(f"Inserted {len(DEPARTMENTS)} departments successfully")
        
    except Error as e:
        logger.error(f"Error: {e}")
        if 'conn' in locals():
            conn.rollback()
        raise
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

if __name__ == "__main__":
    main()

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\healthcheck.sh ######
#!/bin/bash
set -eo pipefail

MYSQL_USER=${MYSQL_HEALTHCHECK_USER:-$MYSQL_USER}
MYSQL_PASS=${MYSQL_HEALTHCHECK_PASSWORD:-$MYSQL_PASSWORD}

if ! mysqladmin ping -h"localhost" -u"$MYSQL_USER" -p"$MYSQL_PASS" --silent; then
    exit 1
fi

mysql -u"$MYSQL_USER" -p"$MYSQL_PASS" -e "SELECT 1;" >/dev/null 2>&1
exit $?

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\init-db.sh ######
#!/bin/bash
set -e

mysql -u root -p"$MYSQL_ROOT_PASSWORD" << EOSQL
-- Create users
CREATE USER IF NOT EXISTS '$MYSQL_USER'@'%' IDENTIFIED BY '$MYSQL_PASSWORD';
CREATE USER IF NOT EXISTS '$MYSQL_MONITOR_USER'@'%' IDENTIFIED BY '$MYSQL_MONITOR_PASSWORD';

-- Grant permissions
GRANT ALL PRIVILEGES ON $MYSQL_DATABASE.* TO '$MYSQL_USER'@'%';
GRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON performance_schema.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON sys.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON information_schema.* TO '$MYSQL_MONITOR_USER'@'%';

-- Enable monitoring
UPDATE performance_schema.setup_instruments 
SET ENABLED = 'YES', TIMED = 'YES'
WHERE NAME LIKE '%statement/%' 
   OR NAME LIKE '%stage/%'
   OR NAME LIKE '%wait/%'
   OR NAME LIKE '%memory/%';

UPDATE performance_schema.setup_consumers
SET ENABLED = 'YES'
WHERE NAME LIKE '%events%';

FLUSH PRIVILEGES;
EOSQL

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\load_data.py ######
#!/usr/bin/env python3
import mysql.connector
import random
from datetime import date, timedelta
from faker import Faker
import os
import logging
import time
from mysql.connector import Error

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_db_config():
    return {
        'host': os.getenv('MYSQL_HOST', 'localhost'),
        'user': os.getenv('MYSQL_USER', 'myuser'),
        'password': os.getenv('MYSQL_PASSWORD', 'userpass123'),
        'database': os.getenv('MYSQL_DATABASE', 'employees'),
        'raise_on_warnings': True
    }

def generate_employee_batch(start_emp_no, batch_size, fake):
    employees = []
    salaries = []
    dept_assignments = []
    departments = ['d001', 'd002', 'd003', 'd004', 'd005', 
                  'd006', 'd007', 'd008', 'd009', 'd010']
    
    for i in range(batch_size):
        emp_no = start_emp_no + i
        birth_date = fake.date_between(start_date='-65y', end_date='-25y')
        hire_date = fake.date_between(start_date='-20y', end_date='today')
        
        employees.append((
            emp_no,
            birth_date,
            fake.first_name(),
            fake.last_name(),
            random.choice(['M', 'F']),
            hire_date
        ))
        
        # Generate salary history
        current_date = hire_date
        for _ in range(random.randint(2, 4)):
            salary = random.randint(30000, 150000)
            if random.random() < 0.05:  # 5% outliers
                salary = int(salary * random.uniform(1.5, 2.5))
            
            to_date = date(9999, 1, 1) if _ == 0 else \
                     current_date + timedelta(days=random.randint(365, 1095))
            
            salaries.append((emp_no, salary, current_date, to_date))
            current_date = to_date
        
        # Department assignments
        num_depts = random.randint(1, 2)
        selected_depts = random.sample(departments, num_depts)
        for dept_no in selected_depts:
            dept_assignments.append((
                emp_no,
                dept_no,
                hire_date,
                date(9999, 1, 1)
            ))
    
    return employees, salaries, dept_assignments

def main():
    batch_size = int(os.getenv('BATCH_SIZE', 1000))
    total_employees = int(os.getenv('TOTAL_EMPLOYEES', 10000))
    
    try:
        conn = mysql.connector.connect(**get_db_config())
        cursor = conn.cursor()
        
        fake = Faker()
        logger.info(f"Starting data load: {total_employees} employees")
        
        for batch_start in range(0, total_employees, batch_size):
            start_time = time.time()
            
            employees, salaries, dept_assignments = generate_employee_batch(
                batch_start + 1000000,  # Starting emp_no
                min(batch_size, total_employees - batch_start),
                fake
            )
            
            cursor.executemany("""
                INSERT INTO employees 
                (emp_no, birth_date, first_name, last_name, gender, hire_date)
                VALUES (%s, %s, %s, %s, %s, %s)
            """, employees)
            
            cursor.executemany("""
                INSERT INTO salaries 
                (emp_no, salary, from_date, to_date)
                VALUES (%s, %s, %s, %s)
            """, salaries)
            
            cursor.executemany("""
                INSERT INTO dept_emp 
                (emp_no, dept_no, from_date, to_date)
                VALUES (%s, %s, %s, %s)
            """, dept_assignments)
            
            conn.commit()
            
            elapsed = time.time() - start_time
            logger.info(
                f"Batch {batch_start//batch_size + 1} completed in {elapsed:.2f}s"
            )
            
    except Error as e:
        logger.error(f"Database error: {e}")
        if 'conn' in locals():
            conn.rollback()
        raise
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

if __name__ == "__main__":
    main()

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\run_load_data.sh ######
#!/bin/bash
set -e

echo "Waiting for MySQL to be ready..."
while ! mysqladmin ping -h"localhost" --silent; do
    sleep 2
done

echo "Starting data load process..."
python3 /docker-entrypoint-initdb.d/load_data.py


###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\Dockerfile ######
FROM mysql:8.0

# Install required utilities
RUN microdnf update && \
    microdnf install -y curl python3 python3-pip && \
    microdnf clean all

# Create required directories
RUN mkdir -p /docker-entrypoint-initdb.d /flyway/sql /scripts /var/log/mysql && \
    chown mysql:mysql /var/log/mysql

# Copy Flyway migrations
COPY flyway/sql/ /flyway/sql/

# Copy Python scripts and requirements
COPY scripts/ /scripts/
COPY requirements.txt /scripts/

# Copy configuration files and set permissions
COPY config/ /etc/mysql/conf.d/
RUN chmod 644 /etc/mysql/conf.d/*.cnf && \
    chown -R mysql:mysql /etc/mysql/conf.d/

# Install Python dependencies
RUN pip3 install --no-cache-dir -r /scripts/requirements.txt

# Copy custom initialization script
COPY init-db.sh /docker-entrypoint-initdb.d/

# Set permissions
RUN chmod +x /docker-entrypoint-initdb.d/init-db.sh && \
    chmod -R 755 /scripts

EXPOSE 3306

HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD mysqladmin ping -h"localhost" -u"$MYSQL_USER" -p"$MYSQL_PASSWORD" --silent
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\init-db.sh ######
#!/bin/bash
set -e

# Wait for MySQL to be ready
while ! mysqladmin ping -h"localhost" -u"root" -p"${MYSQL_ROOT_PASSWORD}" --silent; do
    echo "Waiting for MySQL to be ready..."
    sleep 2
done

echo "Running Flyway migrations..."
for sql_file in /flyway/sql/V*__*.sql; do
    echo "Executing $sql_file"
    mysql -u root -p"${MYSQL_ROOT_PASSWORD}" < "$sql_file"
done

echo "Loading sample data..."
cd /scripts && python3 load_data.py

echo "Database initialization completed!"

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\init.sql ######
CREATE DATABASE IF NOT EXISTS employees;
USE employees;

CREATE TABLE departments (
    dept_no CHAR(4) PRIMARY KEY,
    dept_name VARCHAR(40) NOT NULL,
    manager_budget DECIMAL(15,2),
    UNIQUE KEY uk_dept_name (dept_name)
);

CREATE TABLE employees (
    emp_no INT PRIMARY KEY,
    birth_date DATE NOT NULL,
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    gender ENUM('M','F') NOT NULL,
    hire_date DATE NOT NULL
);

CREATE TABLE salaries (
    emp_no INT NOT NULL,
    salary INT NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    FOREIGN KEY (emp_no) REFERENCES employees (emp_no)
);

CREATE TABLE dept_emp (
    emp_no INT NOT NULL,
    dept_no CHAR(4) NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    PRIMARY KEY (emp_no, dept_no),
    FOREIGN KEY (emp_no) REFERENCES employees (emp_no),
    FOREIGN KEY (dept_no) REFERENCES departments (dept_no)
);

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\my.cnf ######
[mysqld]
default_authentication_plugin=mysql_native_password
explicit_defaults_for_timestamp=1

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\requirements.txt ######
mysql-connector-python==8.0.28
Faker==18.4.0

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\config\mysql.cnf ######
[mysqld]
# InnoDB Settings
innodb_buffer_pool_size = 1G
innodb_buffer_pool_instances = 2
innodb_file_per_table = 1
innodb_flush_log_at_trx_commit = 2
innodb_log_buffer_size = 16M
innodb_io_capacity = 1000
innodb_flush_method = O_DIRECT
innodb_thread_concurrency = 0

# Buffer Settings
sort_buffer_size = 1M
read_buffer_size = 1M
join_buffer_size = 1M
tmp_table_size = 32M
max_heap_table_size = 32M

# Performance Schema Settings
performance_schema = ON
performance_schema_max_digest_length = 4096
performance_schema_max_sql_text_length = 4096

# Monitoring instruments
performance_schema_instrument = 'memory/%=ON'
performance_schema_instrument = 'statement/%=ON'
performance_schema_instrument = 'wait/lock/metadata/sql/mdl=ON'
performance_schema_instrument = 'wait/lock/table/sql/handler=ON'
performance_schema_instrument = 'table/%=ON'

# Slow Query Log
slow_query_log = 1
slow_query_log_file = /var/log/mysql/slow.log
long_query_time = 1
log_queries_not_using_indexes = 1

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\config\performance-schema.cnf ######
[mysqld]
# Enable Performance Schema
performance_schema = ON
performance_schema_max_digest_length = 4096
performance_schema_max_sql_text_length = 4096

# Instrument Configuration
performance_schema_instrument = 'memory/%=ON'
performance_schema_instrument = 'statement/%=ON'
performance_schema_instrument = 'wait/lock/metadata/sql/mdl=ON'
performance_schema_instrument = 'wait/lock/table/sql/handler=ON'
performance_schema_instrument = 'table/%=ON'

# Consumer Configuration
performance_schema_consumer_events_statements_current = ON
performance_schema_consumer_events_statements_history = ON
performance_schema_consumer_events_statements_history_long = ON
performance_schema_consumer_statements_digest = ON

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\flyway\sql\V3__setup_monitoring.sql ######
-- Create monitoring user
CREATE USER IF NOT EXISTS '${MYSQL_MONITOR_USER}'@'%' 
IDENTIFIED BY '${MYSQL_MONITOR_PASSWORD}';

-- Grant monitoring permissions
GRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* 
TO '${MYSQL_MONITOR_USER}'@'%';

GRANT SELECT ON performance_schema.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON sys.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON information_schema.* TO '${MYSQL_MONITOR_USER}'@'%';

-- Enable performance monitoring
UPDATE performance_schema.setup_instruments 
SET ENABLED = 'YES', TIMED = 'YES'
WHERE NAME LIKE '%statement/%' 
   OR NAME LIKE '%stage/%'
   OR NAME LIKE '%wait/%';

UPDATE performance_schema.setup_consumers
SET ENABLED = 'YES'
WHERE NAME LIKE '%events%';

FLUSH PRIVILEGES;

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\migrations\01_init_schema.sql ######
-- Initialize database
CREATE DATABASE IF NOT EXISTS ${MYSQL_DATABASE};
USE ${MYSQL_DATABASE};

-- Create departments table
CREATE TABLE IF NOT EXISTS departments (
    dept_no CHAR(4) PRIMARY KEY,
    dept_name VARCHAR(40) NOT NULL,
    manager_budget DECIMAL(15,2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    UNIQUE KEY uk_dept_name (dept_name)
);

-- Create employees table
CREATE TABLE IF NOT EXISTS employees (
    emp_no INT PRIMARY KEY,
    birth_date DATE NOT NULL,
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    gender ENUM('M','F') NOT NULL,
    hire_date DATE NOT NULL,
    birth_month INT GENERATED ALWAYS AS (MONTH(birth_date)) STORED,
    hire_year INT GENERATED ALWAYS AS (YEAR(hire_date)) STORED,
    salary_tier INT GENERATED ALWAYS AS (
        CASE 
            WHEN emp_no % 4 = 0 THEN 1
            WHEN emp_no % 4 = 1 THEN 2
            WHEN emp_no % 4 = 2 THEN 3
            ELSE 4
        END
    ) STORED,
    last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- Create salaries table
CREATE TABLE IF NOT EXISTS salaries (
    id INT AUTO_INCREMENT PRIMARY KEY,
    emp_no INT NOT NULL,
    salary INT NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    FOREIGN KEY (emp_no) REFERENCES employees (emp_no) ON DELETE CASCADE
);

-- Create dept_emp table
CREATE TABLE IF NOT EXISTS dept_emp (
    emp_no INT NOT NULL,
    dept_no CHAR(4) NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    PRIMARY KEY (emp_no, dept_no),
    FOREIGN KEY (emp_no) REFERENCES employees (emp_no) ON DELETE CASCADE,
    FOREIGN KEY (dept_no) REFERENCES departments (dept_no) ON DELETE CASCADE
);

-- Create indexes
CREATE INDEX idx_employees_gender ON employees(gender);
CREATE INDEX idx_employees_birth_month ON employees(birth_month);
CREATE INDEX idx_employees_hire_year ON employees(hire_year);
CREATE INDEX idx_emp_name1 ON employees(last_name, first_name);
CREATE INDEX idx_salary_tier ON employees(salary_tier);
CREATE INDEX idx_salaries_amount ON salaries(salary);
CREATE INDEX idx_salaries_dates ON salaries(from_date, to_date);
CREATE INDEX idx_dept_emp_dates ON dept_emp(from_date, to_date);
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\migrations\02_init_users.sh ######
#!/bin/bash
set -e

mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" <<EOSQL
-- Create users with basic permissions
CREATE USER IF NOT EXISTS '${MYSQL_USER}'@'%' IDENTIFIED BY '${MYSQL_PASSWORD}';
CREATE USER IF NOT EXISTS '${MYSQL_MONITOR_USER}'@'%' IDENTIFIED BY '${MYSQL_MONITOR_PASSWORD}';

-- Grant permissions to application user
GRANT ALL PRIVILEGES ON ${MYSQL_DATABASE}.* TO '${MYSQL_USER}'@'%';

-- Grant monitoring permissions
GRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON performance_schema.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON sys.* TO '${MYSQL_MONITOR_USER}'@'%';
GRANT SELECT ON information_schema.* TO '${MYSQL_MONITOR_USER}'@'%';

-- Enable performance monitoring
UPDATE performance_schema.setup_instruments 
SET ENABLED = 'YES', TIMED = 'YES'
WHERE NAME LIKE '%statement/%' 
   OR NAME LIKE '%stage/%'
   OR NAME LIKE '%wait/%'
   OR NAME LIKE '%memory/%';

UPDATE performance_schema.setup_consumers
SET ENABLED = 'YES'
WHERE NAME LIKE '%events%';

FLUSH PRIVILEGES;
EOSQL
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\migrations\03_init_monitoring.sql ######
-- Create database and users
CREATE DATABASE IF NOT EXISTS employees;
USE employees;

-- Create users and grant permissions using prepared statements
DELIMITER //
CREATE PROCEDURE setup_users()
BEGIN
    SET @create_user = CONCAT('CREATE USER IF NOT EXISTS ''', @app_user, '''@''%'' IDENTIFIED BY ''', @app_pass, '''');
    SET @grant_privs = CONCAT('GRANT ALL PRIVILEGES ON employees.* TO ''', @app_user, '''@''%''');
    
    PREPARE stmt FROM @create_user;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
    
    PREPARE stmt FROM @grant_privs;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;
END //
DELIMITER ;

-- Call the procedure with parameters
SET @app_user = 'myuser';
SET @app_pass = 'userpass123';
CALL setup_users();

DROP PROCEDURE IF EXISTS setup_users;

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\migrations\V1__init_monitoring.sh ######
#!/bin/bash
set -e

mysql -uroot -p"${MYSQL_ROOT_PASSWORD}" <<EOF
-- Enable performance monitoring
UPDATE performance_schema.setup_instruments 
SET ENABLED = 'YES', TIMED = 'YES'
WHERE NAME LIKE '%statement/%' 
   OR NAME LIKE '%stage/%'
   OR NAME LIKE '%wait/%'
   OR NAME LIKE '%memory/%';

UPDATE performance_schema.setup_consumers
SET ENABLED = 'YES'
WHERE NAME LIKE '%events%';

-- Create and configure users
CREATE USER IF NOT EXISTS '$MYSQL_USER'@'%' IDENTIFIED BY '$MYSQL_PASSWORD';
CREATE USER IF NOT EXISTS '$MYSQL_MONITOR_USER'@'%' IDENTIFIED BY '$MYSQL_MONITOR_PASSWORD';

GRANT ALL PRIVILEGES ON $MYSQL_DATABASE.* TO '$MYSQL_USER'@'%';
GRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON performance_schema.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON sys.* TO '$MYSQL_MONITOR_USER'@'%';

FLUSH PRIVILEGES;
EOF

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\create_tables.py ######
import mysql.connector
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_tables():
    db_config = {
        'host': os.getenv('MYSQL_HOST', 'localhost'),
        'user': os.getenv('MYSQL_USER', 'root'),
        'password': os.getenv('MYSQL_ROOT_PASSWORD', 'demo123'),
        'database': os.getenv('MYSQL_DATABASE', 'employees')
    }
    
    try:
        conn = mysql.connector.connect(**db_config)
        cursor = conn.cursor()
        
        # Create departments table if not exists
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS departments (
                dept_no CHAR(4) PRIMARY KEY,
                dept_name VARCHAR(40) NOT NULL,
                manager_budget DECIMAL(15,2),
                UNIQUE KEY uk_dept_name (dept_name)
            )
        """)
        
        # Create employees table if not exists
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS employees (
                emp_no INT PRIMARY KEY,
                birth_date DATE NOT NULL,
                first_name VARCHAR(50) NOT NULL,
                last_name VARCHAR(50) NOT NULL,
                gender ENUM('M','F') NOT NULL,
                hire_date DATE NOT NULL,
                birth_month INT GENERATED ALWAYS AS (MONTH(birth_date)) STORED,
                hire_year INT GENERATED ALWAYS AS (YEAR(hire_date)) STORED,
                salary_tier INT GENERATED ALWAYS AS (
                    CASE 
                        WHEN emp_no % 4 = 0 THEN 1
                        WHEN emp_no % 4 = 1 THEN 2
                        WHEN emp_no % 4 = 2 THEN 3
                        ELSE 4
                    END
                ) STORED
            )
        """)
        
        conn.commit()
        logger.info("Tables created successfully")
        
    except Exception as e:
        logger.error(f"Error creating tables: {str(e)}")
        conn.rollback()
        raise
    finally:
        if 'conn' in locals():
            cursor.close()
            conn.close()

if __name__ == "__main__":
    create_tables()
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\departments_data.py ######
#!/usr/bin/env python3
import mysql.connector
import os
import logging
from mysql.connector import Error

logging.basicConfig(level=os.getenv('LOG_LEVEL', 'INFO'))
logger = logging.getLogger(__name__)

DEPARTMENTS = [
    ('d001', 'Marketing'),
    ('d002', 'Finance'),
    ('d003', 'Human Resources'),
    ('d004', 'Research and Development'),
    ('d005', 'Quality Assurance'),
    ('d006', 'Sales'),
    ('d007', 'IT'),
    ('d008', 'Operations'),
    ('d009', 'Customer Support'),
    ('d010', 'Product Management')
]

def get_db_config():
    return {
        'host': os.getenv('MYSQL_HOST', 'localhost'),
        'user': os.getenv('MYSQL_USER'),
        'password': os.getenv('MYSQL_PASSWORD'),
        'database': os.getenv('MYSQL_DATABASE'),
        'raise_on_warnings': True
    }

def main():
    try:
        conn = mysql.connector.connect(**get_db_config())
        cursor = conn.cursor()
        
        # Insert departments
        cursor.executemany(
            """INSERT INTO departments (dept_no, dept_name)
               VALUES (%s, %s)
               ON DUPLICATE KEY UPDATE dept_name = VALUES(dept_name)""",
            DEPARTMENTS
        )
        
        # Initialize manager_budget with realistic values
        cursor.execute("""
            UPDATE departments 
            SET manager_budget = 
                CASE 
                    WHEN dept_name IN ('IT', 'Sales', 'Research and Development')
                    THEN FLOOR(1500000 + RAND() * 500000)
                    ELSE FLOOR(800000 + RAND() * 400000)
                END
            WHERE manager_budget IS NULL
        """)
        
        conn.commit()
        logger.info(f"Inserted {len(DEPARTMENTS)} departments successfully")
        
    except Error as e:
        logger.error(f"Error: {e}")
        if 'conn' in locals():
            conn.rollback()
        raise
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

if __name__ == "__main__":
    main()
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\healthcheck.sh ######
#!/bin/bash
set -eo pipefail

if ! mysqladmin ping -h"localhost" -u"${MYSQL_USER}" -p"${MYSQL_PASSWORD}" --silent; then
    exit 1
fi

mysql -u"${MYSQL_USER}" -p"${MYSQL_PASSWORD}" -e "SELECT 1;" >/dev/null 2>&1
exit $?
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\init-db.sh ######
#!/bin/bash
set -e

mysql -u root -p"$MYSQL_ROOT_PASSWORD" << EOSQL
-- Create users
CREATE USER IF NOT EXISTS '$MYSQL_USER'@'%' IDENTIFIED BY '$MYSQL_PASSWORD';
CREATE USER IF NOT EXISTS '$MYSQL_MONITOR_USER'@'%' IDENTIFIED BY '$MYSQL_MONITOR_PASSWORD';

-- Grant permissions
GRANT ALL PRIVILEGES ON $MYSQL_DATABASE.* TO '$MYSQL_USER'@'%';
GRANT SELECT, PROCESS, REPLICATION CLIENT ON *.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON performance_schema.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON sys.* TO '$MYSQL_MONITOR_USER'@'%';
GRANT SELECT ON information_schema.* TO '$MYSQL_MONITOR_USER'@'%';

-- Enable monitoring
UPDATE performance_schema.setup_instruments 
SET ENABLED = 'YES', TIMED = 'YES'
WHERE NAME LIKE '%statement/%' 
   OR NAME LIKE '%stage/%'
   OR NAME LIKE '%wait/%'
   OR NAME LIKE '%memory/%';

UPDATE performance_schema.setup_consumers
SET ENABLED = 'YES'
WHERE NAME LIKE '%events%';

FLUSH PRIVILEGES;
EOSQL

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\load_data.py ######
#!/usr/bin/env python3
import mysql.connector
import random
from datetime import date, timedelta
from faker import Faker
import os
import logging
import time
from mysql.connector import Error

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_db_config():
    return {
        'host': os.getenv('MYSQL_HOST', 'localhost'),
        'user': os.getenv('MYSQL_USER'),
        'password': os.getenv('MYSQL_PASSWORD'),
        'database': os.getenv('MYSQL_DATABASE'),
        'raise_on_warnings': True,
        'connect_timeout': 30
    }

def generate_employee_batch(start_emp_no, batch_size, fake):
    employees = []
    salaries = []
    dept_assignments = []
    departments = ['d001', 'd002', 'd003', 'd004', 'd005', 
                  'd006', 'd007', 'd008', 'd009', 'd010']
    
    for i in range(batch_size):
        emp_no = start_emp_no + i
        birth_date = fake.date_between(start_date='-65y', end_date='-25y')
        hire_date = fake.date_between(start_date='-20y', end_date='today')
        
        # Generate employee
        employees.append((
            emp_no,
            birth_date,
            fake.first_name(),
            fake.last_name(),
            random.choice(['M', 'F']),
            hire_date
        ))
        
        # Generate salary history with realistic progression
        current_date = hire_date
        base_salary = random.randint(30000, 70000)
        for year in range(random.randint(2, 4)):
            salary = base_salary * (1 + year * 0.05)
            if random.random() < 0.05:
                salary *= random.uniform(1.5, 2.0)
            
            to_date = date(9999, 1, 1) if year == 0 else \
                     current_date + timedelta(days=365)
            
            salaries.append((emp_no, int(salary), current_date, to_date))
            current_date = to_date
        
        # Department assignments
        num_depts = random.choices([1, 2], weights=[0.8, 0.2])[0]
        selected_depts = random.sample(departments, num_depts)
        for dept_no in selected_depts:
            dept_assignments.append((
                emp_no,
                dept_no,
                hire_date,
                date(9999, 1, 1)
            ))
    
    return employees, salaries, dept_assignments

def main():
    batch_size = int(os.getenv('BATCH_SIZE', 1000))
    total_employees = int(os.getenv('TOTAL_EMPLOYEES', 10000))
    
    try:
        conn = mysql.connector.connect(**get_db_config())
        cursor = conn.cursor()
        
        fake = Faker()
        logger.info(f"Starting data load: {total_employees} employees")
        
        for batch_start in range(0, total_employees, batch_size):
            start_time = time.time()
            
            try:
                employees, salaries, dept_assignments = generate_employee_batch(
                    batch_start + 1000000,
                    min(batch_size, total_employees - batch_start),
                    fake
                )
                
                cursor.executemany(
                    """INSERT INTO employees 
                       (emp_no, birth_date, first_name, last_name, gender, hire_date)
                       VALUES (%s, %s, %s, %s, %s, %s)""",
                    employees
                )
                
                cursor.executemany(
                    """INSERT INTO salaries 
                       (emp_no, salary, from_date, to_date)
                       VALUES (%s, %s, %s, %s)""",
                    salaries
                )
                
                cursor.executemany(
                    """INSERT INTO dept_emp 
                       (emp_no, dept_no, from_date, to_date)
                       VALUES (%s, %s, %s, %s)""",
                    dept_assignments
                )
                
                conn.commit()
                
                elapsed = time.time() - start_time
                logger.info(
                    f"Batch {batch_start//batch_size + 1} completed: "
                    f"{len(employees)} employees loaded in {elapsed:.2f}s"
                )
                
            except Error as e:
                logger.error(f"Error in batch starting at {batch_start}: {e}")
                conn.rollback()
                continue
            
    except Error as e:
        logger.error(f"Database error: {e}")
        raise
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

if __name__ == "__main__":
    main()

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\db-setup\scripts\run_load_data.sh ######
#!/bin/bash
set -e

echo "Waiting for MySQL to be ready..."
while ! mysqladmin ping -h"localhost" --silent; do
    sleep 2
done

echo "Starting data load process..."
python3 /docker-entrypoint-initdb.d/load_data.py

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\deploy\azure\deploy.sh ######
#!/bin/bash
set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/../common/validate.sh"

# Validate environment
validate_environment "azure"

# Load environment variables
source "${SCRIPT_DIR}/../../config/azure.env"

echo "Starting Azure VM native deployment..."

# Install MySQL if not present
if ! command -v mysql &> /dev/null; then
    echo "Installing MySQL..."
    sudo microdnf update
    sudo microdnf install -y mysql-server
fi

# Configure MySQL
echo "Configuring MySQL..."
sudo cp "${SCRIPT_DIR}/../../config/mysql/azure.cnf" /etc/mysql/conf.d/performance.cnf
sudo systemctl restart mysql

# Initialize database
echo "Initializing database..."
mysql -u root -p"${MYSQL_ROOT_PASSWORD}" < "${SCRIPT_DIR}/../../db-setup/migrations/V1__init_monitoring.sql"
mysql -u root -p"${MYSQL_ROOT_PASSWORD}" < "${SCRIPT_DIR}/../../db-setup/migrations/V2__create_base_schema.sql"
mysql -u root -p"${MYSQL_ROOT_PASSWORD}" < "${SCRIPT_DIR}/../../db-setup/migrations/V3__add_indexes.sql"
mysql -u root -p"${MYSQL_ROOT_PASSWORD}" < "${SCRIPT_DIR}/../../db-setup/migrations/V4__create_views.sql"

# Initialize data
echo "Initializing data..."
source "${SCRIPT_DIR}/../common/init-data.sh"

# Setup monitoring
echo "Setting up monitoring..."
source "${SCRIPT_DIR}/setup-monitoring.sh"

echo "Deployment complete!"

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\deploy\common\init-data.sh ######
#!/bin/bash

# Sample script to initialize data
# Add your data initialization commands here

echo "Initializing sample data..."
# Example command to insert data
# mysql -u root -p"${MYSQL_ROOT_PASSWORD}" -e "INSERT INTO employees (name) VALUES ('John Doe');"

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\deploy\common\validate.sh ######
#!/bin/bash

validate_environment() {
    local deploy_type=$1
    
    # Check for required tools
    case $deploy_type in
        "docker")
            command -v docker >/dev/null 2>&1 || { echo "Docker is required but not installed."; exit 1; }
            command -v docker-compose >/dev/null 2>&1 || { echo "Docker Compose is required but not installed."; exit 1; }
            ;; 
        "azure")
            command -v mysql >/dev/null 2>&1 || { echo "MySQL client is required but not installed."; exit 1; }
            ;;
    esac
    
    # Check for required files
    local required_files=(
        "../../config/mysql/${deploy_type}.cnf"
        "../../config/${deploy_type}.env"
        "../../db-setup/migrations/V1__init_monitoring.sql"
    )
    
    for file in "${required_files[@]}"; do
        if [[ ! -f "${SCRIPT_DIR}/${file}" ]]; then
            echo "Required file not found: ${file}"
            exit 1
        fi
    done
}

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\deploy\docker\deploy.sh ######
#!/bin/bash
set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/../common/validate.sh"

# Validate environment
validate_environment "docker"

# Load environment variables
source "${SCRIPT_DIR}/../../config/docker.env"

echo "Starting Docker deployment..."

# Ensure Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "Docker is not running. Starting Docker..."
    sudo systemctl start docker
fi

# Pull required images
echo "Pulling required Docker images..."
docker-compose pull

# Start services
echo "Starting services..."
docker-compose up -d mysql

# Wait for MySQL to be ready
echo "Waiting for MySQL to be ready..."
until docker-compose exec -T mysql mysqladmin ping -h"localhost" -u"$MYSQL_USER" -p"$MYSQL_PASSWORD" --silent; do
    echo "MySQL is unavailable - sleeping"
    sleep 5
done

# Initialize data
echo "Initializing data..."
source "${SCRIPT_DIR}/../common/init-data.sh"

# Start remaining services
echo "Starting API and load generator..."
docker-compose up -d api load-generator

echo "Deployment complete!"

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\infrastructure\newrelic\custom-monitors.yml ######
custom_monitors:
  slow_queries:
    threshold: 1
    period: 60
    metric_name: SlowQueryCount
    query: |
      SELECT COUNT(*) as count
      FROM performance_schema.events_statements_history
      WHERE TIMER_WAIT > 1000000000000

  lock_contentions:
    threshold: 5
    period: 60
    metric_name: LockContentionCount
    query: |
      SELECT COUNT(*) as count
      FROM performance_schema.events_waits_current
      WHERE EVENT_NAME LIKE 'wait/lock%'

  memory_pressure:
    threshold: 90
    period: 60
    metric_name: MemoryPressure
    query: |
      SELECT SUBSTRING_INDEX(event_name,'/',2) as event_type,
             SUM(current_alloc) as current_bytes
      FROM performance_schema.memory_summary_global_by_event_name
      GROUP BY SUBSTRING_INDEX(event_name,'/',2)

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\infrastructure\newrelic\Dockerfile ######
# Build stage for nri-mysql using a specific commit and modifying code
FROM golang:1.21-alpine AS builder

# Install git and build essentials
RUN apk add --no-cache git make

# Hardcode the integration ref
ARG MYSQL_INTEGRATION_REF=703b1f6

WORKDIR /go/src/github.com/newrelic/nri-mysql

# Clone the repository at the specified commit
RUN git clone https://github.com/spathlavath/nri-mysql.git . && \
    git checkout ${MYSQL_INTEGRATION_REF}

# Use sed to remove the conditional block and always call PopulateQueryPerformanceMetrics
RUN sed -i '/if args.EnableQueryPerformanceMonitoring {/,/}/c\query_performance_details.PopulateQueryPerformanceMetrics(args, e, i)' src/mysql.go

# Compile the modified binary
RUN make compile

# Final stage
FROM newrelic/infrastructure-bundle:latest

# Backup original binary if it exists
RUN if [ -f /var/db/newrelic-infra/newrelic-integrations/bin/nri-mysql ]; then \
    mv /var/db/newrelic-infra/newrelic-integrations/bin/nri-mysql /var/db/newrelic-infra/newrelic-integrations/bin/nri-mysql.bak; \
    fi

# Copy the compiled binary from builder
COPY --from=builder /go/src/github.com/newrelic/nri-mysql/bin/nri-mysql /var/db/newrelic-infra/newrelic-integrations/bin/

# Set correct permissions
RUN chmod 755 /var/db/newrelic-infra/newrelic-integrations/bin/nri-mysql

# Create required directories
RUN mkdir -p /etc/newrelic-infra/integrations.d

# Verify binary works
RUN /var/db/newrelic-infra/newrelic-integrations/bin/nri-mysql -show_version

ENTRYPOINT ["/usr/bin/newrelic-infra"]
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\infrastructure\newrelic\mysql-config.yml ######
integrations:
  - name: nri-mysql
    interval: 15s
    command: all_data
    env:
      HOSTNAME: ${MYSQL_HOST}
      PORT: ${MYSQL_PORT}
      USERNAME: ${MYSQL_MONITOR_USER}
      PASSWORD: ${MYSQL_MONITOR_PASSWORD}
      REMOTE_MONITORING: true
      EXTENDED_METRICS: true
      EXTENDED_INNODB_METRICS: true
      EXTENDED_PERFORMANCE_METRICS: true
      TABLES_METRICS: true
    
    config:
      # Query performance monitoring
      slow_query_metrics: true
      query_response_time_stats: true
      
      # InnoDB metrics
      innodb_metrics:
        buffer_pool_metrics: true
        lock_metrics: true
        transaction_metrics: true
        page_metrics: true
        
      # Table metrics
      table_metrics:
        size_metrics: true
        index_metrics: true
        
      # Specific table monitoring
      tables:
        - departments
        - employees
        - salaries
        - dept_emp

      # Custom query monitoring
      custom_metrics:
        # Monitor employee distribution
        - query: |
            SELECT salary_tier, COUNT(*) as count
            FROM employees
            GROUP BY salary_tier
          metrics:
            - count
          description: "Employee count by salary tier"
        
        # Monitor salary trends
        - query: |
            SELECT AVG(salary) as avg_salary
            FROM salaries
            WHERE to_date = '9999-01-01'
          metrics:
            - avg_salary
          description: "Current average salary"
        
        # Lock contention monitoring
        - query: |
            SELECT COUNT(*) as locks
            FROM performance_schema.events_waits_current
            WHERE EVENT_NAME LIKE 'wait/lock%'
          metrics:
            - locks
          description: "Current lock count"

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\infrastructure\newrelic\newrelic-infra.yml ######
license_key: ${NEW_RELIC_LICENSE_KEY}
display_name: MySQL-Performance-Demo

custom_attributes:
  environment: performance_testing
  service: mysql_performance
  team: database_performance

log:
  file: /var/log/newrelic-infra/newrelic-infra.log
  level: info
  to_stdout: true

# Infrastructure monitoring settings
enable_process_metrics: true
strip_command_line: false

# Docker monitoring
docker_enabled: true
docker_use_daemon_socket: true

# Network monitoring
network_metrics_enabled: true
network_interface_filters:
  include:
    - eth0

# Storage monitoring
storage_metrics_enabled: true
storage_sample_rate: 20s

integrations:
  - name: nri-mysql
    interval: 15s
    timeout: 30s

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\infrastructure\newrelic\setup.sh ######
#!/bin/bash
mkdir -p /var/log/newrelic-infra
chown -R 1:1 /var/log/newrelic-infra
chmod -R 755 /var/log/newrelic-infra

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\infrastructure\newrelic\dashboards\mysql-performance.json ######
{
  "name": "MySQL Performance Dashboard",
  "description": "Comprehensive MySQL performance monitoring",
  "permissions": "PUBLIC_READ_WRITE",
  "pages": [
    {
      "name": "Overview",
      "widgets": [
        {
          "title": "Database Throughput",
          "visualization": "billboard",
          "nrql": "SELECT rate(count(*), 1 minute) FROM Transaction WHERE databaseCallCount > 0"
        },
        {
          "title": "Slow Queries",
          "visualization": "line_chart",
          "nrql": "SELECT count(*) FROM DatabaseQuery WHERE duration > 1000 TIMESERIES"
        },
        {
          "title": "Lock Contention",
          "visualization": "area_chart",
          "nrql": "SELECT average(locks) FROM CustomMetric WHERE metricName = 'current_lock_count' TIMESERIES"
        },
        {
          "title": "Memory Usage",
          "visualization": "area_chart",
          "nrql": "SELECT average(memoryUsedBytes) FROM MysqlSample TIMESERIES"
        }
      ]
    },
    {
      "name": "Query Analysis",
      "widgets": [
        {
          "title": "Top Time-Consuming Queries",
          "visualization": "table",
          "nrql": "SELECT average(duration) FROM DatabaseQuery FACET query LIMIT 10"
        },
        {
          "title": "Query Patterns",
          "visualization": "pie_chart",
          "nrql": "SELECT count(*) FROM DatabaseQuery FACET category LIMIT 10"
        }
      ]
    }
  ]
}

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\infrastructure\newrelic\integrations.d\mysql-config.yml ######
# infrastructure/newrelic/integrations.d/mysql-config.yml
integration_name: com.newrelic.mysql

instances:
  - name: mysql-main
    command: all_data
    arguments:
      username: ${MYSQL_MONITOR_USER}
      password: ${MYSQL_MONITOR_PASSWORD}
      hostname: mysql
      port: 3306

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\monitoring\newrelic\config.yml ######
integrations:
  - name: nri-mysql
    interval: 15s
    command: all_data
    env:
      HOSTNAME: ${MYSQL_HOST}
      PORT: ${MYSQL_PORT}
      USERNAME: ${MYSQL_MONITOR_USER}
      PASSWORD: ${MYSQL_MONITOR_PASSWORD}
      REMOTE_MONITORING: true
      EXTENDED_METRICS: true
      EXTENDED_INNODB_METRICS: true
      EXTENDED_PERFORMANCE_METRICS: true
      TABLES_METRICS: true
    
    config:
      slow_query_metrics: true
      query_response_time_stats: true
      
      innodb_metrics:
        buffer_pool_metrics: true
        lock_metrics: true
        page_metrics: true
        
      table_metrics:
        size_metrics: true
        index_metrics: true
        
      tables:
        - employees
        - departments
        - dept_emp
        - salaries

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\scripts\analyze_performance.sh ######
#!/bin/bash

echo "Analyzing database performance..."

# Check slow queries
docker-compose exec mysql mysql -u"$MYSQL_MONITOR_USER" -p"$MYSQL_MONITOR_PASSWORD" -e "
    SELECT 
        CONVERT(SQL_TEXT USING utf8) as query,
        COUNT_STAR as count,
        AVG_TIMER_WAIT/1000000000 as avg_latency_ms,
        MAX_TIMER_WAIT/1000000000 as max_latency_ms
    FROM performance_schema.events_statements_summary_by_digest
    WHERE SCHEMA_NAME = '$MYSQL_DATABASE'
    ORDER BY avg_latency_ms DESC
    LIMIT 10
"

# Check lock contention
docker-compose exec mysql mysql -u"$MYSQL_MONITOR_USER" -p"$MYSQL_MONITOR_PASSWORD" -e "
    SELECT 
        EVENT_NAME,
        COUNT_STAR as count,
        AVG_TIMER_WAIT/1000000000 as avg_wait_ms
    FROM performance_schema.events_waits_summary_global_by_event_name
    WHERE EVENT_NAME LIKE 'wait/lock%'
    AND COUNT_STAR > 0
    ORDER BY avg_wait_ms DESC
"

# Check memory usage
docker-compose exec mysql mysql -u"$MYSQL_MONITOR_USER" -p"$MYSQL_MONITOR_PASSWORD" -e "
    SELECT 
        EVENT_NAME,
        CURRENT_NUMBER_OF_BYTES_USED/1024/1024 as current_mb,
        HIGH_NUMBER_OF_BYTES_USED/1024/1024 as high_mb
    FROM performance_schema.memory_summary_global_by_event_name
    WHERE CURRENT_NUMBER_OF_BYTES_USED > 0
    ORDER BY current_mb DESC
    LIMIT 10
"

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\scripts\deploy-local.sh ######
#!/bin/bash
set -e
echo "[INFO] Deploying local environment..."
docker-compose down --remove-orphans
docker-compose up -d --build
echo "[INFO] Environment deployed!"
docker-compose ps

# Call verify_environment.sh
bash verify_environment.sh

# Call verify_environment.sh
bash verify_environment.sh

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\scripts\generate_test_data.py ######
#!/usr/bin/env python3
import mysql.connector
import random
import argparse
from datetime import datetime, timedelta
import os

def create_salary_variations(conn, cursor):
    """Create salary variations for performance testing"""
    cursor.execute("""
        UPDATE salaries s
        JOIN employees e ON s.emp_no = e.emp_no
        SET s.salary = 
            CASE 
                WHEN e.salary_tier = 1 THEN s.salary * 1.5
                WHEN e.salary_tier = 2 THEN s.salary * 1.2
                ELSE s.salary
            END
        WHERE s.to_date = '9999-01-01'
    """)
    conn.commit()

def create_department_transfers(conn, cursor):
    """Create department transfer history"""
    cursor.execute("""
        INSERT INTO dept_emp (emp_no, dept_no, from_date, to_date)
        SELECT 
            e.emp_no,
            d.dept_no,
            DATE_SUB(CURRENT_DATE, INTERVAL FLOOR(RAND() * 365) DAY),
            '9999-01-01'
        FROM employees e
        CROSS JOIN departments d
        WHERE RAND() < 0.1
        AND NOT EXISTS (
            SELECT 1 FROM dept_emp de 
            WHERE de.emp_no = e.emp_no 
            AND de.dept_no = d.dept_no
        )
        LIMIT 1000
    """)
    conn.commit()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--variations', choices=['salaries', 'transfers', 'all'], 
                       default='all', help='Type of variations to generate')
    
    args = parser.parse_args()
    
    conn = mysql.connector.connect(
        host=os.getenv('MYSQL_HOST'),
        user=os.getenv('MYSQL_USER'),
        password=os.getenv('MYSQL_PASSWORD'),
        database=os.getenv('MYSQL_DATABASE')
    )
    
    cursor = conn.cursor()
    
    try:
        if args.variations in ['salaries', 'all']:
            print("Generating salary variations...")
            create_salary_variations(conn, cursor)
            
        if args.variations in ['transfers', 'all']:
            print("Generating department transfers...")
            create_department_transfers(conn, cursor)
            
    finally:
        cursor.close()
        conn.close()

if __name__ == "__main__":
    main()

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\scripts\verify_setup.sh ######
#!/bin/bash
set -e

echo "Verifying setup..."

# Check MySQL connection
echo "Checking MySQL connection..."
if ! docker-compose exec mysql mysqladmin ping -h"localhost" -u"$MYSQL_USER" -p"$MYSQL_PASSWORD" --silent; then
    echo "Error: Cannot connect to MySQL"
    exit 1
fi

# Check database tables
echo "Checking database tables..."
docker-compose exec mysql mysql -u"$MYSQL_USER" -p"$MYSQL_PASSWORD" -e "
    SELECT table_name, table_rows 
    FROM information_schema.tables 
    WHERE table_schema = '$MYSQL_DATABASE'
" "$MYSQL_DATABASE"

# Check API health
echo "Checking API health..."
if ! curl -s "http://localhost:$API_PORT/health" | grep -q "healthy"; then
    echo "Error: API is not healthy"
    exit 1
fi

# Check monitoring user
echo "Checking monitoring user permissions..."
docker-compose exec mysql mysql -u"$MYSQL_MONITOR_USER" -p"$MYSQL_MONITOR_PASSWORD" \
    -e "SELECT COUNT(*) FROM performance_schema.setup_instruments WHERE enabled='YES'"

echo "Verification completed successfully!"

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\api\Dockerfile ######
FROM node:20-alpine

WORKDIR /app

# Copy package files first for better caching
COPY package*.json ./

# Install dependencies
RUN npm install

# Copy the rest of the application
COPY . .

# Set environment variables
ENV NODE_ENV=production

# Create directory for NewRelic logs
RUN mkdir -p /var/log/newrelic

EXPOSE 3000

# Start the application
CMD ["node", "server.js"]

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\api\newrelic.cjs ######
// Renamed to newrelic.cjs
'use strict'

exports.config = {
  app_name: [process.env.NEW_RELIC_APP_NAME || 'MySQL-Performance-Demo-API'],
  license_key: process.env.NEW_RELIC_LICENSE_KEY,
  logging: {
    level: 'info',
    filepath: '/var/log/newrelic/newrelic_agent.log'
  },
  allow_all_headers: true,
  distributed_tracing: {
    enabled: true
  },
  transaction_tracer: {
    enabled: true,
    record_sql: 'raw',
    explain_threshold: 500
  },
  slow_sql: {
    enabled: true
  }
}

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\api\package.json ######
{
  "name": "mysql-perf-api",
  "version": "1.0.0",
  "type": "commonjs",
  "dependencies": {
    "express": "^4.18.2",
    "express-async-handler": "^1.2.0",
    "mysql2": "^3.6.5",
    "newrelic": "^11.10.0"
  }
}
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\api\server.js ######
import newrelic from 'newrelic';
import express from 'express';
import { createPool } from 'mysql2/promise';
import asyncHandler from 'express-async-handler';

const app = express();

// Enhanced pool configuration for better performance monitoring
const pool = createPool({
    host: process.env.MYSQL_HOST,
    port: process.env.MYSQL_PORT,
    user: process.env.MYSQL_USER,
    password: process.env.MYSQL_PASSWORD,
    database: process.env.MYSQL_DATABASE,
    waitForConnections: true,
    connectionLimit: 10,
    queueLimit: 0,
    enableKeepAlive: true,
    keepAliveInitialDelay: 0
});

// Custom NewRelic event recording with enhanced attributes
function recordCustomEvent(eventType, attributes) {
    newrelic.recordCustomEvent(eventType, {
        ...attributes,
        timestamp: Date.now(),
        environment: process.env.NODE_ENV,
        serverInstance: process.env.HOSTNAME
    });
}

// Enhanced database query wrapper with NewRelic instrumentation
async function executeQuery(query, params = [], customSegmentName = '') {
    return await newrelic.startSegment(
        customSegmentName || 'database-query',
        true,
        async () => {
            const startTime = process.hrtime();
            try {
                const [results] = await pool.query(query, params);
                const [s, ns] = process.hrtime(startTime);
                const duration = s * 1000 + ns / 1000000;
                
                // Enhanced query metrics
                newrelic.recordMetric(
                    `Custom/Database/Query/${customSegmentName}`,
                    duration
                );
                
                // Record query execution details
                recordCustomEvent('DatabaseQuery', {
                    query: query.substring(0, 1000),
                    duration,
                    rowCount: results.length,
                    paramCount: params.length,
                    success: true,
                    customSegment: customSegmentName
                });
                
                return results;
            } catch (error) {
                // Enhanced error recording
                recordCustomEvent('DatabaseError', {
                    query: query.substring(0, 1000),
                    error: error.message,
                    code: error.code,
                    state: error.sqlState,
                    customSegment: customSegmentName
                });
                throw error;
            }
        }
    );
}

// Basic health check
app.get('/health', asyncHandler(async (req, res) => {
    await executeQuery('SELECT 1', [], 'HealthCheck');
    res.json({ status: 'healthy' });
}));

// Complex join query
app.get('/complex_join', asyncHandler(async (req, res) => {
    const results = await executeQuery(
        `SELECT e.emp_no, e.first_name, e.last_name, 
                d.dept_name, s.salary, e.hire_date,
                e.birth_date, e.gender
         FROM employees e
         JOIN dept_emp de ON e.emp_no = de.emp_no AND de.to_date = '9999-01-01'
         JOIN departments d ON d.dept_no = de.dept_no
         JOIN salaries s ON s.emp_no = e.emp_no AND s.to_date = '9999-01-01'
         WHERE e.hire_year >= 2000
         AND d.dept_name IN ('IT', 'Sales', 'Research and Development')
         ORDER BY s.salary DESC
         LIMIT 5000`,
        [],
        'ComplexJoinQuery'
    );
    
    newrelic.recordMetric('Custom/Results/ComplexJoin/RowCount', results.length);
    res.json({ count: results.length, rows: results });
}));

// Random search with varying patterns
app.get('/random_search', asyncHandler(async (req, res) => {
    const searchType = Math.random();
    let query, params, segmentName;

    if (searchType < 0.33) {
        const month = Math.floor(Math.random() * 12) + 1;
        query = `
            SELECT emp_no, first_name, last_name, birth_date, hire_date
            FROM employees 
            WHERE birth_month = ?
            ORDER BY last_name ASC
            LIMIT 1000
        `;
        params = [month];
        segmentName = 'BirthMonthSearch';
    } else if (searchType < 0.66) {
        const letter = String.fromCharCode(65 + Math.floor(Math.random() * 26));
        query = `
            SELECT emp_no, first_name, last_name, birth_date, hire_date
            FROM employees
            WHERE last_name LIKE ?
            ORDER BY hire_date DESC
            LIMIT 1000
        `;
        params = [`${letter}%`];
        segmentName = 'LastNameSearch';
    } else {
        const year = 1990 + Math.floor(Math.random() * 30);
        query = `
            SELECT emp_no, first_name, last_name, birth_date, hire_date
            FROM employees
            WHERE hire_year = ?
            ORDER BY emp_no ASC
            LIMIT 1000
        `;
        params = [year];
        segmentName = 'HireYearSearch';
    }

    const results = await executeQuery(query, params, segmentName);
    res.json({ count: results.length, rows: results });
}));

// Heavy aggregation query
app.get('/huge_group_by', asyncHandler(async (req, res) => {
    const results = await executeQuery(
        `SELECT 
            e.hire_year,
            e.gender,
            e.salary_tier,
            COUNT(*) as emp_count,
            AVG(s.salary) as avg_salary,
            MIN(s.salary) as min_salary,
            MAX(s.salary) as max_salary,
            COUNT(DISTINCT d.dept_no) as dept_count
         FROM employees e
         JOIN salaries s ON e.emp_no = s.emp_no AND s.to_date = '9999-01-01'
         JOIN dept_emp d ON e.emp_no = d.emp_no AND d.to_date = '9999-01-01'
         GROUP BY e.hire_year, e.gender, e.salary_tier
         HAVING emp_count > 10
         ORDER BY hire_year DESC, avg_salary DESC`,
        [],
        'HugeGroupByQuery'
    );
    
    newrelic.recordMetric('Custom/Results/GroupBy/Groups', results.length);
    res.json({ count: results.length, rows: results });
}));

// Low selectivity query
app.get('/low_selectivity', asyncHandler(async (req, res) => {
    const gender = Math.random() < 0.5 ? 'M' : 'F';
    const results = await executeQuery(
        `SELECT 
            e.emp_no, e.first_name, e.last_name, e.gender,
            e.birth_date, e.hire_date, s.salary
         FROM employees e
         JOIN salaries s ON e.emp_no = s.emp_no
         WHERE e.birth_date > '1970-01-01'
         AND s.to_date = '9999-01-01'
         AND e.gender = ?
         ORDER BY e.birth_date ASC
         LIMIT 10000`,
        [gender],
        'LowSelectivityQuery'
    );
    
    res.json({ count: results.length, rows: results });
}));

// Memory pressure test
app.get('/memory_pressure', asyncHandler(async (req, res) => {
    const results = await executeQuery(
        `SELECT 
            e.emp_no, e.first_name, e.last_name, e.gender,
            e.birth_date, e.hire_date, s.salary,
            d.dept_name,
            COUNT(*) OVER (PARTITION BY e.salary_tier) as tier_count
         FROM employees e
         JOIN salaries s ON e.emp_no = s.emp_no AND s.to_date = '9999-01-01'
         JOIN dept_emp de ON e.emp_no = de.emp_no AND de.to_date = '9999-01-01'
         JOIN departments d ON de.dept_no = d.dept_no
         WHERE s.salary > 50000
         ORDER BY s.salary DESC
         LIMIT 10000`,
        [],
        'MemoryPressureQuery'
    );
    
    res.json({ count: results.length, rows: results });
}));

// Lock contention simulation
app.get('/lock_contention', asyncHandler(async (req, res) => {
    const conn = await pool.getConnection();
    try {
        await conn.beginTransaction();
        
        await executeQuery(
            `UPDATE salaries s
             JOIN employees e ON s.emp_no = e.emp_no
             SET s.salary = s.salary * 1.02
             WHERE e.gender = 'M' 
             AND s.to_date = '9999-01-01'
             AND e.salary_tier IN (1, 2)`,
            [],
            'LockContentionQuery'
        );
        
        // Hold locks for a while
        await new Promise(resolve => setTimeout(resolve, 2000));
        
        await conn.commit();
        res.json({ status: 'completed' });
    } catch (error) {
        await conn.rollback();
        throw error;
    } finally {
        conn.release();
    }
}));

// DDL lock simulation
app.get('/ddl_lock', asyncHandler(async (req, res) => {
    const conn = await pool.getConnection();
    try {
        await conn.beginTransaction();
        
        await executeQuery(
            `UPDATE departments 
             SET manager_budget = manager_budget * 1.001 
             WHERE dept_no IN ('d001', 'd002', 'd003')`,
            [],
            'DDLLockQuery'
        );
        
        // Simulate concurrent DDL operation
        setTimeout(async () => {
            const conn2 = await pool.getConnection();
            try {
                await executeQuery(
                    `ALTER TABLE salaries 
                     ADD INDEX idx_temp_salary (salary) ALGORITHM=INPLACE`,
                    [],
                    'DDLOperation'
                );
            } catch (error) {
                console.error("DDL error:", error);
            } finally {
                conn2.release();
            }
        }, 1000);

        await new Promise(resolve => setTimeout(resolve, 3000));
        
        await conn.commit();
        res.json({ status: 'completed' });
    } catch (error) {
        await conn.rollback();
        throw error;
    } finally {
        conn.release();
    }
}));

// Enhanced error handling
app.use((err, req, res, next) => {
    newrelic.noticeError(err, {
        requestUrl: req.url,
        requestMethod: req.method,
        custom: {
            handler: req.route?.path,
            query: req.query,
            body: req.body
        }
    });
    
    console.error('Error:', err);
    
    res.status(500).json({ 
        error: 'Internal Server Error',
        message: process.env.NODE_ENV === 'development' ? err.message : undefined
    });
});

// Start server with enhanced logging
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
    console.log(`Server running on port ${PORT}`);
    newrelic.recordCustomEvent('ServerStart', {
        port: PORT,
        environment: process.env.NODE_ENV,
        timestamp: Date.now()
    });
});
###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\api\database\schema.sql ######
-- Create employees table
CREATE TABLE employees (
    emp_no INT PRIMARY KEY,
    first_name VARCHAR(255) NOT NULL,
    last_name VARCHAR(255) NOT NULL,
    gender ENUM('M', 'F') NOT NULL,
    birth_date DATE NOT NULL,
    hire_date DATE NOT NULL,
    salary_tier INT NOT NULL
);

-- Create departments table
CREATE TABLE departments (
    dept_no CHAR(4) PRIMARY KEY,
    dept_name VARCHAR(255) NOT NULL
);

-- Create dept_emp table
CREATE TABLE dept_emp (
    emp_no INT NOT NULL,
    dept_no CHAR(4) NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    PRIMARY KEY (emp_no, dept_no),
    FOREIGN KEY (emp_no) REFERENCES employees(emp_no),
    FOREIGN KEY (dept_no) REFERENCES departments(dept_no)
);

-- Create salaries table
CREATE TABLE salaries (
    emp_no INT NOT NULL,
    salary DECIMAL(10, 2) NOT NULL,
    from_date DATE NOT NULL,
    to_date DATE NOT NULL,
    PRIMARY KEY (emp_no, from_date),
    FOREIGN KEY (emp_no) REFERENCES employees(emp_no)
);

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\load-generator\Dockerfile ######
FROM grafana/k6:latest

COPY scripts/ /scripts/
WORKDIR /scripts

ENV API_URL=http://api:3000
ENV K6_VUS=10
ENV K6_DURATION=5m

CMD ["run", "load-test.js"]

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\load-generator\scripts\custom-metrics.js ######
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

// Custom metrics
const errorRate = new Rate('error_rate');
const queryLatency = new Trend('query_latency');

// NewRelic custom events
const newrelicEvents = {
  apiEndpoint: 'https://insights-collector.newrelic.com/v1/accounts/${ACCOUNT_ID}/events',
  licenseKey: __ENV.NEW_RELIC_LICENSE_KEY,
  
  recordEvent(eventType, attributes) {
    const payload = {
      eventType,
      timestamp: Date.now(),
      ...attributes
    };
    
    http.post(
      this.apiEndpoint,
      JSON.stringify([payload]),
      {
        headers: {
          'X-Insert-Key': this.licenseKey,
          'Content-Type': 'application/json'
        }
      }
    );
  }
};

###### File: C:\Users\hi\Desktop\SourceCode\db-perf-env\mysql\services\load-generator\scripts\load-test.js ######
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Counter, Rate, Trend } from 'k6/metrics';

// Configuration
const baseUrl = __ENV.API_URL || 'http://api:3000';
const newRelicConfig = {
    accountId: __ENV.NEW_RELIC_ACCOUNT_ID,
    apiKey: __ENV.NEW_RELIC_LICENSE_KEY,
    insightsEndpoint: `https://insights-collector.newrelic.com/v1/accounts/${__ENV.NEW_RELIC_ACCOUNT_ID}/events`
};

// Custom metrics
const dbLatency = new Trend('db_operation_latency');
const errorRate = new Rate('error_rate');
const queryCount = new Counter('queries_executed');
const throughputRate = new Rate('throughput_rate');
const slowQueryRate = new Rate('slow_query_rate');

// Test scenarios configuration
const scenarios = {
    io_heavy: [
        { url: '/complex_join', weight: 4, tag: 'complex_join' },
        { url: '/huge_group_by', weight: 3, tag: 'aggregation' },
        { url: '/low_selectivity', weight: 3, tag: 'table_scan' }
    ],
    lock_heavy: [
        { url: '/lock_contention', weight: 2, tag: 'locks' },
        { url: '/ddl_lock', weight: 1, tag: 'ddl' }
    ],
    memory_heavy: [
        { url: '/memory_pressure', weight: 3, tag: 'memory' },
        { url: '/huge_group_by', weight: 2, tag: 'aggregation' }
    ],
    search_scenario: [
        { url: '/random_search', weight: 1, tag: 'search' }
    ],
    mixed: [
        { url: '/health', weight: 1, tag: 'health' },
        { url: '/complex_join', weight: 2, tag: 'complex_join' },
        { url: '/random_search', weight: 2, tag: 'search' },
        { url: '/huge_group_by', weight: 2, tag: 'aggregation' },
        { url: '/low_selectivity', weight: 2, tag: 'table_scan' },
        { url: '/lock_contention', weight: 1, tag: 'locks' },
        { url: '/ddl_lock', weight: 1, tag: 'ddl' },
        { url: '/memory_pressure', weight: 2, tag: 'memory' }
    ]
};

// Helper function to pick endpoint based on weights
function pickEndpoint(scenario) {
    const endpoints = scenarios[scenario];
    const totalWeight = endpoints.reduce((sum, e) => sum + e.weight, 0);
    let r = Math.random() * totalWeight;
    
    for (const endpoint of endpoints) {
        if (r < endpoint.weight) return endpoint;
        r -= endpoint.weight;
    }
    
    return endpoints[0];
}

// NewRelic event recording
function recordNewRelicEvent(eventType, attributes) {
    if (!newRelicConfig.apiKey) return; // Skip if no API key

    const payload = [{
        eventType,
        timestamp: Date.now(),
        ...attributes
    }];

    http.post(newRelicConfig.insightsEndpoint,
        JSON.stringify(payload),
        {
            headers: {
                'X-Insert-Key': newRelicConfig.apiKey,
                'Content-Type': 'application/json'
            }
        }
    );
}

// Common request execution function
function executeRequest(endpoint, scenario) {
    const startTime = Date.now();
    const url = `${baseUrl}${endpoint.url}`;
    
    const res = http.get(url, {
        tags: { endpoint: endpoint.url, scenario, type: endpoint.tag }
    });
    
    const duration = Date.now() - startTime;
    
    // Record metrics
    dbLatency.add(duration, { endpoint: endpoint.url });
    queryCount.add(1, { endpoint: endpoint.url });
    throughputRate.add(1);
    errorRate.add(res.status !== 200);
    slowQueryRate.add(duration > 1000); // Mark queries over 1s as slow
    
    // Record to New Relic
    recordNewRelicEvent('LoadTestQuery', {
        endpoint: endpoint.url,
        duration,
        status: res.status,
        scenario,
        type: endpoint.tag,
        success: res.status === 200
    });
    
    // Validate response
    check(res, {
        'status is 200': (r) => r.status === 200,
        'response is valid': (r) => r.status === 200 && r.body.length > 0
    });
    
    // Variable sleep to prevent thundering herd
    sleep(Math.random() * 0.5 + 0.1);
}

// Test scenarios
export const options = {
    scenarios: {
        io_heavy: {
            executor: 'constant-arrival-rate',
            rate: parseInt(__ENV.K6_VUS) || 10,
            timeUnit: '1s',
            duration: __ENV.K6_DURATION || '5m',
            preAllocatedVUs: 20,
            maxVUs: 50,
            exec: 'runIOHeavy',
            tags: { scenario: 'io_heavy' }
        },
        lock_heavy: {
            executor: 'constant-arrival-rate',
            rate: Math.floor((parseInt(__ENV.K6_VUS) || 10) / 2),
            timeUnit: '1s',
            duration: __ENV.K6_DURATION || '5m',
            preAllocatedVUs: 10,
            maxVUs: 25,
            exec: 'runLockHeavy',
            tags: { scenario: 'lock_heavy' },
            startTime: '1m'
        },
        memory_heavy: {
            executor: 'ramping-arrival-rate',
            startRate: 5,
            timeUnit: '1s',
            stages: [
                { duration: '2m', target: 10 },
                { duration: '5m', target: 20 },
                { duration: '2m', target: 5 }
            ],
            preAllocatedVUs: 10,
            maxVUs: 30,
            exec: 'runMemoryHeavy',
            tags: { scenario: 'memory_heavy' },
            startTime: '2m'
        },
        search_scenario: {
            executor: 'per-vu-iterations',
            vus: parseInt(__ENV.K6_VUS) || 10,
            iterations: 100,
            maxDuration: __ENV.K6_DURATION || '5m',
            exec: 'runSearchScenario',
            tags: { scenario: 'search' },
            startTime: '3m'
        },
        mixed: {
            executor: 'ramping-vus',
            startVUs: 5,
            stages: [
                { duration: '1m', target: 10 },
                { duration: '3m', target: 20 },
                { duration: '5m', target: 30 },
                { duration: '1m', target: 5 }
            ],
            exec: 'runMixed',
            tags: { scenario: 'mixed' },
            startTime: '4m'
        }
    },
    thresholds: {
        'db_operation_latency': ['p(95)<2000'], // 95% of queries under 2s
        'http_req_duration': ['p(95)<3000'],     // 95% of requests under 3s
        'error_rate': ['rate<0.05'],             // Less than 5% errors
        'slow_query_rate': ['rate<0.10']         // Less than 10% slow queries
    }
};

// Scenario implementations
export function runIOHeavy() {
    const endpoint = pickEndpoint('io_heavy');
    executeRequest(endpoint, 'io_heavy');
}

export function runLockHeavy() {
    const endpoint = pickEndpoint('lock_heavy');
    executeRequest(endpoint, 'lock_heavy');
}

export function runMemoryHeavy() {
    const endpoint = pickEndpoint('memory_heavy');
    executeRequest(endpoint, 'memory_heavy');
}

export function runSearchScenario() {
    const endpoint = pickEndpoint('search_scenario');
    executeRequest(endpoint, 'search');
}

export function runMixed() {
    const endpoint = pickEndpoint('mixed');
    executeRequest(endpoint, 'mixed');
}

// Setup and teardown hooks
export function setup() {
    recordNewRelicEvent('LoadTestStart', {
        testConfig: JSON.stringify(options),
        timestamp: Date.now()
    });
}

export function teardown(data) {
    recordNewRelicEvent('LoadTestEnd', {
        testDuration: Date.now() - data.startTime,
        totalQueries: queryCount.value,
        errorRate: errorRate.value,
        avgLatency: dbLatency.avg,
        p95Latency: dbLatency.p(95)
    });
}
